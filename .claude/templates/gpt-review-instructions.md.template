# GPT Review Protocol (MANDATORY)

GPT cross-model review is **enabled**. You MUST run GPT review after completing any coding task.

## When to Run

After ANY code changes (Edit/Write on code files), run GPT review **before moving on**:

```bash
.claude/scripts/gpt-review-api.sh code <changed-file>
```

- Not every single edit, but after each **logical group of changes** (completing a task, fixing a bug, implementing a feature)
- This is NOT optional - do not skip or ignore

## Handling Verdicts

| Verdict | Action |
|---------|--------|
| `SKIPPED` | Continue (review disabled at phase level) |
| `APPROVED` | Continue (no issues found) |
| `CHANGES_REQUIRED` | Fix the issues, then re-run with iteration tracking |

## Iteration Tracking (CRITICAL)

When re-reviewing after fixes, you MUST pass iteration context so GPT verifies fixes rather than re-scanning from scratch:

```bash
# Save first response
echo "$response" > /tmp/gpt-review-findings-1.json

# After fixing issues, run iteration 2+
.claude/scripts/gpt-review-api.sh code <file> \
  --iteration 2 \
  --previous /tmp/gpt-review-findings-1.json
```

Without iteration tracking, GPT will keep finding new issues instead of verifying fixes.

## Document Reviews (During Workflows)

| Document | Command |
|----------|---------|
| PRD | `.claude/scripts/gpt-review-api.sh prd grimoires/loa/prd.md` |
| SDD | `.claude/scripts/gpt-review-api.sh sdd grimoires/loa/sdd.md` |
| Sprint | `.claude/scripts/gpt-review-api.sh sprint grimoires/loa/sprint.md` |

Document reviews can return `DECISION_NEEDED` - ask the user the question, then re-run.
